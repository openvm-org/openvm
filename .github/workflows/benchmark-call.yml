name: "Benchmark: running individual benchmarks"

on:
  workflow_dispatch:
    inputs:
      benchmark_name:
        type: string
        required: true
        description: The name of the benchmark to run
        default: fibonacci
      runner:
        type: string
        required: false
        description: Runner config as JSON, use {"family":"g6.2xlarge","image":"ubuntu24-gpu-x64"} for GPU
        default: '{"family":"g6.2xlarge","image":"ubuntu24-gpu-x64"}'
      memory_allocator:
        type: string
        required: false
        description: Memory allocator to use (mimalloc or jemalloc)
        default: jemalloc
      app_log_blowup:
        type: number
        required: false
        description: Application level log blowup
        default: 2
      leaf_log_blowup:
        type: number
        required: false
        description: Aggregation (leaf) level log blowup
        default: 2
      root_log_blowup:
        type: number
        required: false
        description: Root level log blowup (only for e2e)
        default: 2
      internal_log_blowup:
        type: number
        required: false
        description: Internal level log blowup (only for e2e)
        default: 2
      max_segment_length:
        type: number
        required: false
        description: Max segment length for continuations, must be larger than 524288
        default: 1048476
      e2e_bench:
        type: boolean
        required: true
        description: Whether to run the e2e benchmark
      features:
        type: string
        required: false
        description: Host features, comma separated (aggregation,perf-metrics)
        default: cuda
  workflow_call:
    inputs:
      benchmark_name:
        type: string
        required: true
        description: The name of the benchmark to run
      benchmark_id:
        type: string
        required: true
        description: The id of the benchmark to run, must be unique within matrix
      runner:
        type: string
        required: false
        description: Runner config as JSON, use {"family":"g6.2xlarge","image":"ubuntu24-gpu-x64"} for GPU
        default: '{"family":"g6.2xlarge","image":"ubuntu24-gpu-x64"}'
      memory_allocator:
        type: string
        required: false
        description: Memory allocator to use (mimalloc or jemalloc)
        default: jemalloc
      app_log_blowup:
        type: number
        required: false
        description: Application level log blowup
        default: 2
      leaf_log_blowup:
        type: number
        required: false
        description: Aggregation (leaf) level log blowup
        default: 2
      root_log_blowup:
        type: number
        required: false
        description: Root level log blowup (only for e2e)
        default: 2
      internal_log_blowup:
        type: number
        required: false
        description: Internal level log blowup (only for e2e)
        default: 2
      max_segment_length:
        type: number
        required: false
        description: Max segment length for continuations, must be larger than 524288
        default: 1048476
      e2e_bench:
        type: boolean
        required: true
        description: Whether to run the e2e benchmark
      features:
        type: string
        required: false
        description: Host features, comma separated (aggregation,perf-metrics)
        default: cuda

env:
  S3_METRICS_PATH: s3://openvm-public-data-sandbox-us-east-1/benchmark/github/metrics
  S3_FLAMEGRAPHS_PATH: s3://openvm-public-data-sandbox-us-east-1/benchmark/github/flamegraphs
  FEATURE_FLAGS: "metrics,parallel,nightly-features"
  INPUT_ARGS: ""
  CARGO_NET_GIT_FETCH_WITH_CLI: "true"

permissions:
  contents: write

jobs:
  build:
    runs-on:
      - runs-on=${{ github.run_id }}
      - runner=test-gpu-nvidia
      - extras=s3-cache

    steps:
      - uses: runs-on/action@v2
      - uses: actions/checkout@v5
      - uses: dtolnay/rust-toolchain@stable
      - uses: Swatinem/rust-cache@v2
        with:
          cache-on-failure: true
      - uses: taiki-e/install-action@nextest

      - name: Check CUDA status and set environment variables
        run: |
          nvcc --version

      - name: Run tests for primitives
        working-directory: crates/circuits/primitives
        run: |
          CUDA_OPT_LEVEL=1 cargo nextest run cuda --features parallel,cuda,touchemall

      - name: Run tests for poseidon2-air
        working-directory: crates/circuits/poseidon2-air
        run: |
          CUDA_OPT_LEVEL=1 cargo nextest run cuda --features parallel,cuda,touchemall
